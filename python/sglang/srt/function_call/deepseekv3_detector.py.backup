import json
import logging
import re
from typing import List

from sglang.srt.function_call.base_format_detector import BaseFormatDetector
from sglang.srt.function_call.core_types import (
    StreamingParseResult,
    StructureInfo,
    ToolCallItem,
    _GetInfoFunc,
)
from sglang.srt.function_call.ebnf_composer import EBNFComposer
from sglang.srt.function_call.utils import _is_complete_json
from sglang.srt.openai_api.protocol import Tool

logger = logging.getLogger(__name__)


class DeepSeekV3Detector(BaseFormatDetector):
    """
    Detector for DeepSeek models.
    Assumes function call format:
      '<｜tool▁call▁begin｜>function'sget_current_weather\n```json\n{"location": "Tokyo"}\n```<｜tool▁call▁end｜>\n<｜tool▁call▁begin｜>function'sget_current_weather\n```json\n{"location": "Paris"}\n```<｜tool▁call▁end｜><｜tool▁calls▁end｜>
    """

    def __init__(self):
        super().__init__()
        self.bot_token = "<｜tool▁call▁begin｜>"
        self.eot_token = "<｜tool▁calls▁end｜>"
        self.func_call_regex = r"<｜tool▁call▁begin｜>.*?<｜tool▁call▁end｜>"
        self.func_detail_regex = r"<｜tool▁call▁begin｜>(.*) (.*)\n```json\n(.*)\n```<｜tool▁call▁end｜>"
        self._last_arguments = ""
        self.current_tool_id = -1

    def has_tool_call(self, text: str) -> bool:
        """Check if the text contains a deepseek format tool call."""
        return self.bot_token in text

    def detect_and_parse(self, text: str, tools: List[Tool]) -> StreamingParseResult:
        """
        One-time parsing: Detects and parses tool calls in the provided text.

        :param text: The complete text to parse.
        :param tools: List of available tools.
        :return: ParseResult indicating success or failure, consumed text, leftover text, and parsed calls.
        """
        idx = text.find(self.bot_token)
        normal_text = text[:idx].strip() if idx != -1 else text
        if self.bot_token not in text:
            return StreamingParseResult(normal_text=normal_text, calls=[])
        match_result_list = re.findall(self.func_call_regex, text, re.DOTALL)
        calls = []
        try:
            for match_result in match_result_list:
                # Get function name
                func_detail = re.search(self.func_detail_regex, match_result, re.DOTALL)
                func_name = func_detail.group(2)
                func_args = func_detail.group(3)
                func_args = json.loads(func_args)
                # construct match_result for parse_base_json
                match_result = {"name": func_name, "parameters": func_args}
                calls.extend(self.parse_base_json(match_result, tools))
            return StreamingParseResult(normal_text=normal_text, calls=calls)
        except Exception as e:
            logger.error(f"Error in detect_and_parse: {e}")
            # return the normal text if parsing fails
            return StreamingParseResult(normal_text=text)

    def parse_streaming_increment(
        self, new_text: str, tools: List[Tool]
    ) -> StreamingParseResult:
        """
        Streaming incremental parsing tool calls for DeepSeekV3 format.
        Buffers complete tool calls and emits them at once for better UI compatibility.
        """
        self._buffer += new_text
        current_text = self._buffer

        # Check if we have a tool call (either the start token or individual tool call)
        has_tool_call = (
            self.bot_token in current_text or "<｜tool▁call▁begin｜>" in current_text
        )

        if not has_tool_call:
            self._buffer = ""
            for e_token in [self.eot_token, "```", "<｜tool▁call▁end｜>"]:
                if e_token in new_text:
                    new_text = new_text.replace(e_token, "")
            return StreamingParseResult(normal_text=new_text)

        if not hasattr(self, "_tool_indices"):
            self._tool_indices = {
                tool.function.name: i
                for i, tool in enumerate(tools)
                if tool.function and tool.function.name
            }

        calls: list[ToolCallItem] = []
        try:
            # Look for complete tool call pattern (from begin to end)
            complete_tool_call_pattern = r"<｜tool▁call▁begin｜>.*?<｜tool▁call▁end｜>"
            complete_match = re.search(complete_tool_call_pattern, current_text, re.DOTALL)
            
            if complete_match:
                # We have a complete tool call - parse it using the existing regex
                match_result = complete_match.group(0)
                func_detail = re.search(self.func_detail_regex, match_result, re.DOTALL)
                
                if func_detail:
                    func_name = func_detail.group(2)
                    func_args = func_detail.group(3)
                    
                    try:
                        # Parse and validate JSON
                        parsed_args = json.loads(func_args)
                        
                        # Initialize tool call ID if needed
                        if self.current_tool_id == -1:
                            self.current_tool_id = 0
                        
                        # Create complete tool call using existing parse_base_json method
                        match_data = {"name": func_name, "parameters": parsed_args}
                        tool_calls = self.parse_base_json(match_data, tools)
                        
                        # Convert to ToolCallItem format expected by streaming
                        for tool_call in tool_calls:
                            calls.append(ToolCallItem(
                                tool_index=self.current_tool_id,
                                name=tool_call.name,
                                parameters=json.dumps(tool_call.parameters) if isinstance(tool_call.parameters, dict) else tool_call.parameters
                            ))
                        
                        # Remove processed tool call from buffer
                        self._buffer = current_text[complete_match.end():]
                        self.current_tool_id += 1
                        
                        return StreamingParseResult(normal_text="", calls=calls)
                        
                    except json.JSONDecodeError:
                        # JSON not complete yet, continue buffering
                        return StreamingParseResult(normal_text="", calls=[])
                else:
                    # Complete tool call found but couldn't parse details
                    logger.error(f"Could not parse tool call details from: {match_result}")
                    self._buffer = ""
                    return StreamingParseResult(normal_text=current_text)
            
            # Check if we have start of a tool call but not complete yet
            if "<｜tool▁call▁begin｜>" in current_text:
                # Buffer until we have complete tool call
                return StreamingParseResult(normal_text="", calls=[])
                
            # No tool call patterns, return as normal text
            self._buffer = ""
            return StreamingParseResult(normal_text=current_text, calls=[])

        except Exception as e:
            logger.error(f"Error in parse_streaming_increment: {e}")
            self._buffer = ""
            return StreamingParseResult(normal_text=current_text)

    def structure_info(self) -> _GetInfoFunc:
        return lambda name: StructureInfo(
            begin=">" + name + "\n```json\n",
            end="\n```<",
            trigger=">" + name + "\n```json\n",
        )

    def build_ebnf(self, tools: List[Tool]):
        return EBNFComposer.build_ebnf(
            tools,
            sequence_start_token=self.bot_token,
            sequence_end_token=self.eot_token,
            tool_call_separator="",
            call_rule_fmt='"<｜tool▁call▁begin｜>function":{"name"}\\n```json\\n" {arguments_rule} "\\n```<｜tool▁call▁end｜>"',
            function_format="json",
        )